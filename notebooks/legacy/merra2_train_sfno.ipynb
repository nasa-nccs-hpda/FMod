{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spherical Fourier Neural Operators\n",
    "\n",
    "A simple notebook to showcase spherical Fourier Neural Operators operating on MERRA2 data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "%matplotlib ipympl\n",
    "import torch\n",
    "import hydra\n",
    "from typing import Dict\n",
    "from fmod.base.util.dates import date_list\n",
    "from fmod.base.util.config import configure, cfg, start_date,  cfg2args\n",
    "# from torch_harmonics.examples.sfno import SphericalFourierNeuralOperatorNet as SFNO\n",
    "from fmod.model.sfno.network import SphericalFourierNeuralOperatorNet as SFNO, sfno_network_parms\n",
    "from fmod.plot.training_results import ResultsPlotter\n",
    "from fmod.controller.trainer import ModelTrainer\n",
    "from data.merra2 import MERRA2Dataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "hydra.initialize(version_base=None, config_path=\"../config\")\n",
    "configure('merra2-sr')\n",
    "\n",
    "# set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device.index)"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data\n",
    "to train our geometric FNOs, we require training data. To this end let us prepare a Dataloader which computes results on the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "dataset = MERRA2Dataset( train_dates=date_list( start_date( cfg().task ), cfg().task.max_steps ), vres=\"high\" )\n",
    "trainer = ModelTrainer( dataset )\n",
    "sfno_args: Dict = cfg2args( \"model\", sfno_network_parms )\n",
    "model = SFNO(  img_size=trainer.grid_shape, **sfno_args ).to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# pointwise model for sanity checking\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  input_dim = 3,\n",
    "#                  output_dim = 3,\n",
    "#                  num_layers = 2,\n",
    "#                  hidden_dim = 32,\n",
    "#                  activation_function = nn.ReLU,\n",
    "#                  bias = False):\n",
    "#         super().__init__()\n",
    "    \n",
    "#         current_dim = input_dim\n",
    "#         layers = []\n",
    "#         for l in range(num_layers-1):\n",
    "#             fc = nn.Conv2d(current_dim, hidden_dim, 1, bias=True)\n",
    "#             # initialize the weights correctly\n",
    "#             scale = sqrt(2. / current_dim)\n",
    "#             nn.init.normal_(fc.weight, mean=0., std=scale)\n",
    "#             if fc.bias is not None:\n",
    "#                 nn.init.constant_(fc.bias, 0.0)\n",
    "#             layers.append(fc)\n",
    "#             layers.append(activation_function())\n",
    "#             current_dim = hidden_dim\n",
    "#         fc = nn.Conv2d(current_dim, output_dim, 1, bias=False)\n",
    "#         scale = sqrt(1. / current_dim)\n",
    "#         nn.init.normal_(fc.weight, mean=0., std=scale)\n",
    "#         if fc.bias is not None:\n",
    "#             nn.init.constant_(fc.bias, 0.0)\n",
    "#         layers.append(fc)\n",
    "#         self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.mlp(x)\n",
    "\n",
    "# model = MLP(num_layers=10).to(device)"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train( model )\n",
    "inputs, targets, predictions = trainer.inference()"
   ],
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plotter = ResultsPlotter( dataset, targets, predictions )\n",
    "plotter.plot()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# s = 0; ch = 0\n",
    "# print( f'Input shape: {inp.shape}, Output shape: {out.shape}, type = {type(inp)} ')\n",
    "# input_image = inp[s, ch]\n",
    "# vmin, vmax = gridops.color_range(input_image,2.0)\n",
    "# \n",
    "# fig = plt.figure()\n",
    "# im = gridops.plot_griddata(input_image, fig, projection='3d', title='input', vmin=vmin, vmax=vmax )\n",
    "# plt.colorbar(im)\n",
    "# plt.show()\n",
    "# \n",
    "# fig = plt.figure()\n",
    "# im = gridops.plot_griddata(out[s, ch], fig, projection='3d', title='prediction', vmin=vmin, vmax=vmax )\n",
    "# plt.colorbar(im)\n",
    "# plt.show()\n",
    "# \n",
    "# fig = plt.figure()\n",
    "# im = gridops.plot_griddata(tar[s, ch], fig, projection='3d', title='target', vmin=vmin, vmax=vmax )\n",
    "# plt.colorbar(im)\n",
    "# plt.show()\n",
    "# \n",
    "# fig = plt.figure()\n",
    "# im = gridops.plot_griddata((tar-out)[s, ch], fig, projection='3d', title='error', vmin=vmin, vmax=vmax )\n",
    "# plt.colorbar(im)\n",
    "# plt.show()"
   ],
   "metadata": {},
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
