{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cape Basin Super Resolution\n",
    "\n",
    "A simple notebook to test assorted SR models operating on the Cape Basin dataset\n",
    "\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import torch\n",
    "import xarray as xa, numpy as np\n",
    "import hydra, os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "from fmod.view.sres import mplplot, create_plot_data\n",
    "from fmod.base.util.config import fmconfig, cfg\n",
    "from fmod.controller.dual_trainer import ModelTrainer\n",
    "from fmod.controller.dual_trainer import LearningContext\n",
    "from fmod.model.sres.manager import SRModels\n",
    "from fmod.data.batch import BatchDataset\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.initialize(version_base=None, config_path=\"../config\")\n",
    "\n",
    "task=\"sres\"\n",
    "model=\"edsr\"\n",
    "dataset=\"LLC4320\"\n",
    "scenario=\"s1\"\n",
    "fmconfig( task, model, dataset, scenario )\n",
    "# lgm().set_level( logging.DEBUG )\n",
    "\n",
    "load_state  = \"current\"\n",
    "save_state  = True \n",
    "cfg().task['nepochs'] = 3\n",
    "eval_tileset = LearningContext.Validation\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device.index)\n",
    "    \n",
    "print( cfg().model.name )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data\n",
    "Prepare a Dataloader which computes results on the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset:  BatchDataset  = BatchDataset( cfg().task, vres=\"low\", )\n",
    "target_dataset: BatchDataset  = BatchDataset( cfg().task, vres=\"high\" )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": [
    "model_manager: SRModels = SRModels( input_dataset, target_dataset, device )\n",
    "trainer:   ModelTrainer = ModelTrainer( model_manager ) \n",
    "sample_input:  xa.DataArray = model_manager.get_sample_input() \n",
    "sample_target: xa.DataArray = model_manager.get_sample_target()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": "train_losses: Dict[str,float] = trainer.train( load_state=load_state, save_state=save_state )",
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata:  Dict[str,xa.DataArray] = {}\n",
    "if len(train_losses) > 0:\n",
    "    inp, targ, prod, ups = trainer.get_current_input(), trainer.get_current_target(), trainer.get_current_product(), trainer.get_current_upsampled()\n",
    "    pdata = create_plot_data( inp, targ, prod, ups, sample_input, sample_target  )\n",
    "    pdata['domain'] = target_dataset.load_global_timeslice()\n",
    "mplplot( pdata, LearningContext.Training, fsize=6.0, losses=train_losses )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validating the Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "eval_losses = trainer.evaluate( eval_tileset )"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inp, targ, prod, ups = trainer.get_current_input(), trainer.get_current_target(), trainer.get_current_product(), trainer.get_current_upsampled()\n",
    "pdata:  Dict[str,xa.DataArray] = create_plot_data( inp, targ, prod, ups, sample_input, sample_target  )\n",
    "mplplot( pdata, LearningContext.Validation, fsize=6.0, losses=eval_losses )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
